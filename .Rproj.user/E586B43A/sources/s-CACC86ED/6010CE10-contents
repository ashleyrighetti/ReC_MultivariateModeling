
# Moderated Mediation {#ModMed}

<!-- TODO: Add link. -->
 [Screencasted Lecture Link]() 

```{r eliminates scientific notation}
options(scipen=999)#eliminates scientific notation
```

The focus of this lecture is the moderated mediation.  That is, are the effects of the indirect effect (sign, significance, strength, presence/absence) *conditional* on the effects of the moderator.

At the outset, please note that although I rely heavily on Hayes [-@hayes_introduction_2018] text and materials, I am using the R package *lavaan* in these chapters.  Very recently, Hayes has introduced a [PROCESS macro for R](https://www.processmacro.org/index.html). Because I am not yet up-to-speed on using this macro (it is not a typical R package) and because we will use *lavaan* for confirmatory factor analysis and structural equation modeling, I have chosen to utilize the *lavaan* package.  A substantial difference is that the PROCESS macros use ordinary least squares and *lavaan* uses maximum likelihood estimators.

## Navigating this Lesson

There is about ## minutes of lecture.  If you work through the materials with me it would be plan for an additional ###

While the majority of R objects and data you will need are created within the R script that sources the chapter, ocasionally there are some that cannot be created from within the R framework. Additionally, sometimes links fail.  All original materials are provided at the [Github site](https://github.com/lhbikos/ReC_MultivariateModeling) that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER's [introduction](#ReCintro)

### Learning Objectives

Learning objectives from this lecture include the following:

* Recognize conditional process modeling from R script.
* Using the R package *lavaan*, 
  - specify a model with indirect effects,
  - identify and interpret B weights, *p* values, and *CIs* for total, direct, and indirect effects,   - calculate the total effects of X and M on Y, 
  - identify the proportion of variance accounted for in predicting M and Y.
* Define and interpret the index of moderated mediation?
* Outline a process of evaluating a moderated mediation in a "piecemeal" (Hayes) approach to model building
* Regarding conditional indirect effects
  - Interpret an index of moderated mediation
  - Know the essential components of calculating an index of moderated mediation
  - How would you probe a conditional indirect effect
* Be able to interpret "the usual" things we find in regression:  B/beta weights, R, $R^{2}$, and figures

### Planning for Practice

The suggestions for homework are graded in complexity and, if you like, can extend from the prior chapter on simple moderation. If you choose the first or second options, you can further amend the simulated data by making further variations such as sample size.

* Rework the problem in the chapter by changing the random seed in the code that simulates the data.  This should provide minor changes to the data, but the results will likely be very similar.
* There are a number of variables in the dataset.  Swap out one or more variables in the moderated mediation and compare your solution to the one in the chapter (and/or oe you mimicked in the journal article).
* Conduct a moderated mediation with data to which you have access. This could include data you simulate on your own or from a published article.


### Readings & Resources

In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.

* Hayes, A. F. (2018). *Introduction to mediation, moderation, and conditional process anlaysis:  A regression-based approach*. New York, NY: Guilford Press. Available as an ebook from the SPU library:  https://ebookcentral-proquest-com.ezproxy.spu.edu/lib/spu/detail.action?docID=5109647 
  - **Chapter 11, CPA fundamentals**:  In this chapter Hayes disentangles conditional indirect effects.  We work a great example on workplace teams where we test the conditional indirect effect on the b path.  
  - **Chapter 12, More CPA examples**:  Among the examples is one that includes covariates.  
  - **Appendix A:  Using Process**:  An essential tool for PROCESS users because, even when we are in the R environment, this is the "idea book." That is, the place where all the path models are presented in figures.
* Lewis, J. A., Williams, M. G., Peppers, E. J., & Gadson, C. A. (2017). Applying intersectionality to explore the relations between gendered racism and health among Black women. *Journal of Counseling Psychology, 64*(5), 475â€“486. https://doi-org.ezproxy.spu.edu/10.1037/cou0000231


### Packages

The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.

<!-- TODO: Build out this section. -->
```{r Install Packages}
#will install the package if not already installed
if(!require(lavaan)){install.packages("lavaan")}
if(!require(semPlot)){install.packages("semPlot")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(psych)){install.packages("psych")}
```

## Conditional Process Analysis

### The definitional and conceptual

Hayes [-@hayes_introduction_2018] coined the term and suggests we also talk about "conditional process modeling."

**Conditional process analysis**:  used when the analytical goal is to describe and understand the conditional nature of the mechanism or mechanisms by which a variable transmits its effect on another.

We are integrating moderation and mediation mechanisms together into a single integrated analytical model. 

* **Mediator**: Any causal system in which at least one causal antecedent X variable is proposed as influencing an outcome Y through a intervening variable M.  In this model, there are two pathways by which X can influence Y:  *direct* effect of X on Y, and *indirect* effect of X on Y through M. 
  * Answers question, "How does X affect Y"
  * Partitions the X-to-Y relationship into two paths of influence: direct, indirect.
  * Indirect effect contains two componetns (a,b) that when multipled (a*b) yield an estimate of how much these two cases that differ by one unit on X are estimated to differ on Y through the effect of X on M, which in turn affects Y.
  * Keywords: how, through, via, indirect effect
* **Moderator**:  The effect of X on some variable Y is moderated by W if its size, sign, or strength depends on or can be predicted by W.
  * Stated another way, W and X *interact* in their influence on Y.  
  * Moderators help establish the boundary conditions of an effect or the circumstances, stimuli, or type of people for which the effect is large v. small, present v. absent, positive v. negative, and so forth.
  * Keywords:  "it depends," interaction effect.

**Why engage both mediators and moderators?**  Hayes suggest that if we have only a mediator(s) in the model that we lose information if we "reduce complex responses that no doubt differ from person to person or situation to situation" (p. 394).  He adds that "all effects are moderated by something" (p. 394). Correspondingly, he recommends we add them to a mediation anlaysis.

Hayes suggests that "more complete" (p. 395) analyses model the mechanisms at work linking X to Y (mediator[s]) while simultaneously allowing those effects to be contingent on context, circumstance, or individual difference (moderator[s]).

**Conditional direct and indirect effects**.  Mediation analyses produce indirect (the product of a sequence of effects that are assumed to be causal) and direct (the unique contribution of X to Y, controlling for other variables in the model) effects.  These effects (the X-to-Y/direct and X-to-W-to-Y/indirect), can also be moderated.  This is our quest! Figure 11.2 in Hayes' text illustrates conceptually and statistically that we can specify moderation of any combination of direct and indirect paths/effects.

![Image of conditional process analysis model where the moderator is hypothesized to change the a path; the path between the IV and mediator](images/SimpleMed/CPAmodel.jpg)

Within the CPA framework we have lots of options that generally fall into two categories:

* *Moderated mediation*:  when an indirect effect of X on Y through M is moderated; the mechanism represented by the *X-to-M-to-Y* chain of events operates to varying degrees (or not at all) for certain people or in certain contexts. 
  * Any model in which the indirect effect (a*b) changes as a function of one or more moderators.  These moderators can be operating on the a, b, or c' paths or any possible combination of the three
  * X could moderate its own indirect effect on Y through M if the effect of M on Y depends on X, or
  * The indirect effect of X on Y through M could be contingent on a fourth variable if that fourth variable W moderates one or more of the relationships in a three-variable causal system, or
  * An indirect effect could be contingent on a moderator variable

* *Mediated moderation*:  an interaction between X and some moderator W on Y is carried through a mediator M; 
  * mediated moderation analysis is simply a mediation analysis with the product of two variables serving as the causal agent of focus
  * An interaction between a moderator W and causal agent X on outcome Y could operate through a mediator M

Hayes argues that the mediated moderation hypotheses are "regularly articulated and tested by scientists" (p. 459).  He warns, though, that we should not confuse the "abundance of published examples of mediated moderation anlayses...with the meaningfulness of the procedure itself" (p. 460).  He later adds that mediation moderation is "neither interesting nor meaningful."  Why?  

*  Conceptualizing a process in terms of a mediated moderation misdirects attention toward a variable in the model that actually doesn't measure anything.
*   Most often there are moderated mediation models that are identical in equations and resulting coefficients - the difference is in the resulting attentional focus and interpretation.
*   Hayes recommends that models proposing mediated moderation be recast in terms of moderated mediation process.
*   Consequently, we will not work a mediated moderation, but there is an example in chapter 12.

### Hayes' PieceMeal Approach to Building Models

In summarizing a strategic approach for testing structural equation models, Joreskog (1993) identified three scenarios:

* *strictly confirmatory*:  the traditional NHST approach of proposing a single, theoretically derived, model, and after analyzing the data either rejects or fails to reject the model.  No further modifications are made/allowed.
* *alternative models*:  the reseacher proposes competing (also theoretically derived) models.  Following analysis of a single set of empirical data, he or she selects one model as appropriate in representing the sample data.
* *model generating*:  A priori, the researcher acknowledges that they may/may not find what they have theoretically proposed. So, a priori, they acknowledge that in the absence of ideal fit (which is the usual circumstance), they will proceed in an exploratory fashion to respecify/re-estimate the model.  The goal is to find a model that is both substantively meaningful and statistically well-fitting.

A legacy of our field is the *strictly confirmatory* approach.  I am thrilled when I see research experts (e.g., Byrne, McCoach/O'Connell) openly endorse a model building approach.  In Chapter 12, Hayes demonstrates what he terms a "piecemeal" approach to building (and understanding) a complex model.


### Some points Hayes wants you to *get* in this chapter

* Absence of an association between X and Y (total effect) does not mean that X isn't causally influencing Y in some manner.  Why?
    + Correlation is not a necessary condition of cause
    + Absence of correlation doesn't say anything about whether the relationship between X and Y is dependent upon (e.g., moderated by) something else.
    
## Workflow for Moderated Mediation



## Simple Mediation in *lavaan*:  A focus on the mechanics

The lavaan tutorial [@rosseel_lavaan_2020] provides a helpful model of how writing code to estimate an indirect effect. Using the lavaan tutorial as our guide, let's start with just a set of fake data with variable names that represent X (predictor, IV, antecedent), M (mediator, atencedent, consequent), and Y (outcome, DV, consequent). 

### Simulate Fake Data

The code below is asking to create a datase with a sample size of 100.  The dataset has 3 variables, conveniently named X (predictor, antecedent, IV), M (mediator), and Y (outome, consequent, DV).  The R code asks for random selection of numbers with a normal distribution.  You can see that the M variable will be related to the X variable by + .5; and the Y variable will be related to the M variable by + .7.  This rather ensures a statistically significant indirect effect.

<!-- TODO: Return and replace with data from our mediation) -->

```{r Simulating fake data}
set.seed(210410)
X <- rnorm(100)
M <- 0.5*X + rnorm(100)
Y <- 0.7*M + rnorm(100)
Data <- data.frame(X = X, Y = Y, M = M)
```


### Specify the Moderated Mediation Model



```{r Coefficients and p values for inline text for the fake data example, echo = FALSE, results ='hide'}
library(formattable) #to use the digits function
FDa <- digits(FD_ParamEsts$est[3], 3) #B weight for the a path
FDa
FDa_p <- digits(FD_ParamEsts$pvalue[3], 3)#p value for the a path
FDa_p
FDb <- digits(FD_ParamEsts$est[1], 3) #B weight for the b path
FDb
FDb_p <- digits(FD_ParamEsts$pvalue[1], 3)#p value for the b path
FDb_p
FDc_p <- digits(FD_ParamEsts$est[2], 3) #B weight for the c' path
FDc_p
FDc_p_p <- digits(FD_ParamEsts$pvalue[2], 3)#p value for the c' path
FDc_p_p
FDtot <-  digits(FD_ParamEsts$est[12], 3)#p value for the c' path
FDtot
FDtot_p <- digits(FD_ParamEsts$pvalue[12], 3)#p value for the c' path
FDtot_p

# Hand calculating the indirect effect
FDind <- digits(FD_ParamEsts$est[3] * FD_ParamEsts$est[1], 3)
FDind <- digits(FDind, 3)
FDind

FDind_p <- digits(FD_ParamEsts$pvalue[10], 3) #p value for the indirect effect
FDind_p

# Proportio of variance accounted for

Rsq_Y <- percent(FDsummary$PE$est[13])
Rsq_Y
Rsq_M <- percent(FDsummary$PE$est[14])
Rsq_M
```

### Interpret the Output


### A Table and a Figure



### Results



## Research Vignette

The research vignette comes from the Lewis, Williams, Peppers, and Gadson's [-@lewis_applying_2017] study titled, "Applying Intersectionality to Explore the Relations Between Gendered Racism and Health Among Black Women."  The study was published in the Journal of Counseling Psychology. Participants were 231 Black women who completed an online survey. 

Variables used in the study included:

* **GRMS**:  Gendered Racial Microaggressions Scale [@lewis_construction_2015] is a 26-item scale that assesses the frequency of nonverbal, verbal, and behavioral negative racial and gender slights experienced by Black women. Scaling is along six points ranging from 0 (never) to 5 (once a week or more).  Higher scores indicate a greater frequency of gendered racial microaggressions. An example item is, "Someone has made a sexually inappropriate comment about my butt, hips, or thighs."

* **MntlHlth** and **PhysHlth**: Short Form Health Survey - Version 2 [@ware_comparison_1995] is a 12-item scale used to report self-reported mental (six items) and physical health (six items).
Higher scores indicate higher mental health (e.g., little or no psychological ldistress) and physical health (e.g., little or no reported symptoms in physical functioning). An example of an item assessing mental health was, "How much of the time during the last 4 weeks have you felt calm and peaceful?"; an example of a physical health item was, "During the past 4 weeks, how much did pain interfere with your normal work?"

* **Sprtlty**, **SocSup**, **Engmgt**, and **DisEngmt** are four subscales from the Brief Coping with Problems Experienced Inventory [@carver_you_1997]. The 28 items on this scale are presented on a 4-point scale ranging from 1 (*I usually do not do this at all*) to 4(*I usually do this a lot*).  Higher scores indicate a respondents' tendency to engage in a particular strategy.  Instructions were modified to ask how the female participants responded to recent experiences of racism and sexism as Black women. The four subscales included spirituality (religion, acceptance, planning), interconnectedness/social support (vent emotions, emotional support,instrumental social support), problem-oriented/engagement coping (active coping, humor, positive reinterpretation/positive reframing), and disengagement coping (behavioral disengagement, substance abuse, denial, self-blame, self-distraction).

* **GRIcntlty**:  The Multidimensional Inventory of Black Identity Centrality subscale [@sellers_multidimensional_nodate] was modified to measure the intersection of racial and gender identity centrality.  The scale included 10 items scaled from 1 (*strongly disagree*) to 7 (*strongly agree*). An example item was, "Being a *Black woman* is important to my self-image."  Higher scores indicated higher levels of gendered racial identity centrality.

### Simulating the data from the journal article

First, we simulate the data from the means, standard deviations, and correlation matrix from the journal article.

```{r Create covariance matrix}
#Entering the intercorrelations, means, and standard deviations from the journal article
LEWmu <- c(1.99, 2.82, 2.48, 2.32, 1.75, 5.71, 21.37, 21.07)
LEWsd <- c(.90, .70, .81, .61, .53, 1.03, 3.83, 4.66)
LEWr_mat <- matrix (c(1, .20, .28, .30, .41, .19, -.32, -.18,
        .20, 1, .49, .57, .22, .13, -.06, -.13,
        .28, .49, 1, .46, .26, .38, -.18,-.08, 
        .30, .57, .46,  1, .37, .08, -.14, -.06,
        .41, .22, .26, .37, 1, .05, -.54, -.28, 
        .19, .13, .38, .08, .05, 1, -.10, .14, 
        -.32, -.06, -.18, -.14, -.54, -.10, 1, .47,
        -.18, -.13, -.08, -.06, -.28, .14, .47, 1), ncol = 8)
#Creating a covariance matrix

LEWcov_mat <- LEWsd %*% t(LEWsd) * LEWr_mat
LEWcov_mat
```

```{r }
#Set random seed so that the following matrix always gets the same results.
set.seed(210403)
library(MASS)
Lewis_df <- mvrnorm(n = 212, mu=LEWmu, Sigma = LEWcov_mat, empirical = TRUE)
colMeans(Lewis_df)
#Checking our work against the original correlation matrix
cor(Lewis_df)
```

Rename the variables
```{r Rename Variables, results='hide'}
as.data.frame(Lewis_df, row.names = NULL, optional = FALSE, make.names = TRUE)
library(tidyverse)
Lewis_df <- Lewis_df%>%
  as.data.frame %>%
  rename(GRMS = V1, Sprtlty = V2, SocSup = V3, Engmgt = V4, DisEngmt = V5, GRIcntlty = V6, MntlHlth = V7, PhysHlth = V8)
```

```{r}
head(Lewis_df)
```

```{r}
library(psych)
psych::describe(Lewis_df)
```



### Specify the Model in *lavaan*

I am a big fan of "copying the model."  In specifying my model I used our simple mediation template above 

* replaced the Y, X, and M with variables names
* replacing the name of the df
* updated the object names (so I could use them in the same .rmd file)

```{r Simple Med w Fake Data}
library(lavaan)
set.seed(210410) #reset in case you choose to separate these sections
model <- '
          PWB ~ b*CMI + c_p*REMS 
          CMI ~a*REMS
          
          indirect :=  a*b
          direct  := c_p
          total_c  := c_p + (a*b)
          '
```

```{r Fit stats from Kim et al, results='hide'}
Kim_fit <- sem(model, data = Kim_df, se="bootstrap", missing= 'fiml')
```

```{r Essential results from Kim et al}
Kim_summary <- summary(Kim_fit, standardized=T, rsq=T, fit=TRUE, ci=TRUE)
Kim_ParamEsts <- parameterEstimates(Kim_fit, boot.ci.type = "bca.simple", standardized=TRUE)
Kim_summary
Kim_ParamEsts
```

```{r Coefficients and p values for inline text for the Kim et al example, echo = FALSE, results ='hide'}
library(formattable) #to use the digits function
# Values for the intercept of the IV
K_Yicpt <- digits(Kim_ParamEsts$est[7], 3) #B weight for the intercept
K_Yicpt 
K_Yicpt_SE <- digits(Kim_ParamEsts$se[7], 3)#p value for the intercept
K_Yicpt_SE
K_Yicpt_p <- digits(Kim_ParamEsts$pvalue[7], 3)#p value for the intercept
K_Yicpt_p

# Values for the intercept of the mediator
K_Micpt <- digits(Kim_ParamEsts$est[8], 3) #B weight for the intercept
K_Micpt 
K_Micpt_SE <- digits(Kim_ParamEsts$se[8], 3)#p value for the intercept
K_Micpt_SE
K_Micpt_p <- digits(Kim_ParamEsts$pvalue[8], 3)#p value for the intercept
K_Micpt_p

# Values for the labeled paths:  a, b, c'
Ka <- digits(Kim_ParamEsts$est[3], 3) #B weight for the a path
Ka
Ka_p <- digits(Kim_ParamEsts$pvalue[3], 3)#p value for the a path
Ka_p
Ka_SE <- digits(Kim_ParamEsts$se[3], 3)#p value for the a path
Ka_SE
Kb <- digits(Kim_ParamEsts$est[1], 3) #B weight for the b path
Kb
Kb_SE <- digits(Kim_ParamEsts$se[1], 3)#SE for the a path
Kb_SE
Kb_p <- digits(Kim_ParamEsts$pvalue[1], 3)#p value for the b path
Kb_p
Kc_p <- digits(Kim_ParamEsts$est[2], 3) #B weight for the c' path
Kc_p
Kc_p_p <- digits(Kim_ParamEsts$pvalue[2], 3)#p value for the c' path
Kc_p_p
Kc_p_SE <- digits(Kim_ParamEsts$se[2], 3)#SE for the c' path
Kc_p_SE

# Values for the total effect
Ktot <-  digits(Kim_ParamEsts$est[12], 3)#B weight for the total effect
Ktot
Ktot_p <- digits(Kim_ParamEsts$pvalue[12], 3)#p value for the total effect
Ktot_p
Ktot_CIlo <- digits(Kim_ParamEsts$ci.lower[12], 3) #lower confidence interval
Ktot_CIlo
Ktot_CIhi <- digits(Kim_ParamEsts$ci.upper[12], 3) #upper confidence interval
Ktot_CIhi

# Values for the direct effect
Kdir <-  digits(Kim_ParamEsts$est[11], 3)#B weight for the direct effect
Kdir
Kdir_p <- digits(Kim_ParamEsts$pvalue[11], 3)#p value for the direct effect
Kdir_p
Kdir_CIlo <- digits(Kim_ParamEsts$ci.lower[11], 3) #lower confidence interval
Kdir_CIlo
Kdir_CIhi <- digits(Kim_ParamEsts$ci.upper[11], 3) #upper confidence interval
Kdir_CIhi

# Values for the indirect effect
Kind <- digits(Kim_ParamEsts$est[10], 3) #estimate for the indirect efect
Kind
Kind_p <- digits(Kim_ParamEsts$pvalue[10], 3) #p value for the indirect effect
Kind_p

Kind_CIlo <- digits(Kim_ParamEsts$ci.lower[10], 3) #lower confidence interval
Kind_CIlo
Kind_CIhi <- digits(Kim_ParamEsts$ci.upper[10], 3) #upper confidence interval
Kind_CIhi

# Proportion of variance accounted for
K_Rsq_Y <- percent(Kim_summary$PE$est[13])
K_Rsq_Y
K_Rsq_M <- percent(Kim_summary$PE$est[14])
K_Rsq_M
```


### Interpret the Output

*  Overall, our model accounted for `r K_Rsq_Y` of the variance in the IV and `r K_Rsq_M` of the variance in the mediator.
*  a path = `r Ka`, $p$ = `r Ka_p`
*  b path = `r Kb`, $p$ = `r Kb_p`
*  the indirect effect is a product of the a and b paths (`r Kind`); while we don't hand calculate it's significance, we see that it is $p$ = `r Kind_p`; the bias-corrected bootstrapped confidence intervals can sometimes be more lenient than $p$ values; it is important they don't cross zero.  They don't:  CI95 `r Kind_CIlo` to `r Kind_CIhi`  
*  the direct effect (c', c prime, or c_p) is the isolated effect of X on Y when including M.  We hope this value is LOWER than the total effect because this means that including M shared some of the variance in predicting Y:  c' = `r Kc_p`, $p$ = `r Kc_p_p`, and it is no longer signifcant.
*  we also see the total effect; this value is 
  + identical to the value of simply predicting Y on X (with no M it the model)
  + the value of a(b) + c_p:  `r Ka`(`r Kb`) + `r Kc_p` =  `r Ktot` ($p$ = `r Ktot_p`)
  
### A Figure and a Table

I make it a practice to immediately plot what I did. Because the plotting packages use our models, this can be a helpful self-check of our work.

```{r semPLOT of PMI}
library(semPlot)
semPaths(Kim_fit, #must identiy the model you want to map
         what = "est", #"est" plots the estimates, but keeps it greyscale with no fading
         #whatLabels = "stand", #"stand" changes to standardized values
         layout = 'tree', rotation = 2, #together, puts predictors on left, IVs on right 
         edge.label.cex = 1.00, #font size of parameter values
         #edge.color = "black", #overwrites the green/black coloring
         sizeMan=10, #size of squares/observed/"manifest" variables
         fade=FALSE, #if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals
         esize=2, 
         asize=3,
         #label.prop = .5,
         label.font = 2.5, #controls size (I think) of font for labels
         label.scale = TRUE, #if false, the labels will not scale to fit inside the nodes
         nDigits = 3, #decimal places (default is 2)
         residuals = FALSE,#excludes residuals (and variances) from the path diagram
         nCharNodes = 0, #specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)
         intercepts = FALSE, #gets rid of those annoying triangles (intercepts) in the path diagram)
)
title("Depression by Racial Microaggressions via Cultural Mistrust")
```

The semTable package can be used to write results to an outfile.
```{r PMI mediation table, results='hide'}
library(semTable)
fitTab1 <- semTable(Kim_fit, columns = c("est", "se", "p", "rsquare"),  columnLabels = c(eststars = "Estimate"), paramSets = c("composites", "loadings", "slopes", "intercepts", "residualvariances"), file = "pmi_fitTABLE", type = "csv", print.results = TRUE)
```

For the purpose of the OER, and because it's good trainng, I also think it can be useful to make our own table.  For me, it facilitates my conceptual understanding of (a) what the statistic is doing and (b) the results of our specific data.

Table 1  

|Model Coefficients Assessing Cultural Mistrust as a Mediator Between Racial Microaggressions and Well-Being
|:-------------------------------------------------------------------------------------------------------------------|

|                         
|:------------------------|:---------------------------------------:|:-----:|:--------------------------------------:|
|                         |Cultural Mistrust (M)                    |       |Well-Being (Y)                          |

|
|:----------------|:-----:|:----------:|:------------:|:-----------:|:-----:|:---------:|:------------:|:-----------:|
|Antecedent       |path   |$B$         |$SE$          |$p$          |path   |$B$        |$SE$          |$p$          |
|constant         |$i_{M}$|`r K_Micpt` |`r K_Micpt_SE`|`r K_Micpt_p`|$i_{Y}$|`r K_Yicpt`|`r K_Yicpt_SE`|`r K_Yicpt_p`|
|REMS (X)         |$a$    |`r Ka`      |`r Ka_SE`     |`r Ka_p`     |$c'$   |`r Kc_p`   |`r Kc_p_SE`   |`r Kc_p_p`   |
|CMI (M)          |       |            |              |             |$b$    |`r Kb`     |`r Kb_SE`     |`r Kb_p`     |

|
|:------------------------|:---------------------------------------:|:-----:|:--------------------------------------:|
|                         |$R^2$ = `r K_Rsq_M`                      |       |$R^2$ = `r K_Rsq_Y`                     |

### Results

A simple mediation model examined the degree to which cultural mistrust mediated the relation of racial microaggressions on depressive symptoms  Using the *lavaan* package (v 0.6-7) in R, coefficients for  each path, the indirect effect, and total effects were calculated. These values are presented in Table 1 and illustrated in Figure 1.  Results suggested that `r K_Rsq_M` of the variance in cultural mistrust and `r K_Rsq_Y`of the variance in depression were accounted for by the model.  When the mediator was included in the model, bias-corrected confidence intervals surrounding the indirect effect  ($B$ = `r Kind`, $p$ = `r Kind_p`, CI95 `r Kind_CIlo` to `r Kind_CIhi`) supported its statistical significance.  While the value of the direct effect ($B$ = `r Kdir`, $p$ = `r Kdir_p`, CI95 `r Kdir_CIlo` to `r Kdir_CIhi`) was somewhat smaller than the total effect ($B$ = `r Ktot`, $p$ = `r Ktot_p`, CI95 `r Ktot_CIlo` to `r Ktot_CIhi`), both remained statistically significant.    


## Considering Covariates

Hayes Chapter 4 [-@hayes_introduction_2018] considers the role of covariates (e.g., other variables that could account for some of the variance in the model).  When previous research (or commonsense, or detractors) suggest you should include them...its worth a try.  If they are non-significant and/or your variables continue to explain variance over-and-above their contribution, then you have gained ground in ruling out plausible rival hypotheses and are adding to causal evidence.

They are relatively easy to specify in *lavaan*.  Just look at to where the arrows point and then write the path!

Let's say we are concerned that anxiety covaries with cultural mistrust and depression.  We'll add it as a covariate to both.

```{r specify ESTRESS w covs}
set.seed(210410)
Kim_fit_covs <- '
          PWB ~ b*CMI + c_p*REMS 
          CMI ~a*REMS
          CMI ~ covM*ANX
          PWB ~ covY*ANX

          indirect :=  a*b
          direct  := c_p
          total_c  := c_p + (a*b)
          '
Kim_fit_covs <- sem(Kim_fit_covs, data = Kim_df, se="bootstrap", missing = 'fiml')
Kcov_sum <- summary(Kim_fit_covs, standardized=T, rsq=T, fit=TRUE, ci=TRUE)
Kcov_ParEsts<- parameterEstimates(Kim_fit_covs, boot.ci.type = "bca.simple", standardized=TRUE)
Kcov_sum
Kcov_ParEsts
```

```{r Coefficients and p values for inline text for the Kim et al example w covs, echo = FALSE, results ='hide'}
library(formattable) #to use the digits function

# Values for the intercept of the IV
Cov_Yicpt <- digits(Kcov_ParEsts$est[11], 3) #B weight for the intercept
Cov_Yicpt 
Cov_Yicpt_SE <- digits(Kcov_ParEsts$se[11], 3)#p value for the intercept
Cov_Yicpt_SE
Cov_Yicpt_p <- digits(Kcov_ParEsts$pvalue[11], 3)#p value for the intercept
Cov_Yicpt_p

# Values for the intercept of the mediator
Cov_Micpt <- digits(Kcov_ParEsts$est[12], 3) #B weight for the intercept
Cov_Micpt 
Cov_Micpt_SE <- digits(Kcov_ParEsts$se[12], 3)#p value for the intercept
Cov_Micpt_SE
Cov_Micpt_p <- digits(Kcov_ParEsts$pvalue[12], 3)#p value for the intercept
Cov_Micpt_p

Cova <- digits(Kcov_ParEsts$est[3], 3) #B weight for the a path
Cova
CovaSE <- digits(Kcov_ParEsts$se[3], 3) #SE for the a path
CovaSE
Cova_p <- digits(Kcov_ParEsts$pvalue[3], 3)#p value for the a path
Cova_p

Covb <- digits(Kcov_ParEsts$est[1], 3) #B weight for the b path
Covb
CovbSE <- digits(Kcov_ParEsts$se[1], 3) #sE for the b path
CovbSE
Covb_p <- digits(Kcov_ParEsts$pvalue[1], 3)#p value for the b path
Covb_p

Covc_p <- digits(Kcov_ParEsts$est[2], 3) #B weight for the c' path
Covc_p
CovcSE <- digits(Kcov_ParEsts$se[2], 3) #SE for the c' path
CovcSE
Covc_p_p <- digits(Kcov_ParEsts$pvalue[2], 3)#p value for the c' path
Covc_p_p

AnxMa <- digits(Kcov_ParEsts$est[4], 3) #B weight for the covariate to M
AnxMa
AnxMse <- digits(Kcov_ParEsts$se[4], 3) #SE for the covariate to M
AnxMse
AnxM_p <- digits(Kcov_ParEsts$pvalue[4], 3)#p for the covariate to M
AnxM_p

AnxYa <- digits(Kcov_ParEsts$est[5], 3) #B weight for the covariate to M
AnxYa
AnxYse <- digits(Kcov_ParEsts$se[5], 3) #SE for the covariate to M
AnxYse
AnxY_p <- digits(Kcov_ParEsts$pvalue[5], 3)#p for the covariate to M
AnxY_p


Covtot <-  digits(Kcov_ParEsts$est[17], 3)#p value for the total effect
Covtot
Covtot_p <- digits(Kcov_ParEsts$pvalue[17], 3)#p value for the total effect
Covtot_p

# Values for the indirect effect
COVind <- digits(Kcov_ParEsts$est[15], 3) #estimate for the indirect effect
COVind
COVind_p <- digits(Kcov_ParEsts$pvalue[15], 3) #p value for the indirect effect
COVind_p
COV_CIlo <- digits(Kcov_ParEsts$ci.lower[15], 3) #lower confidence interval
COV_CIlo
COV_CIup <- digits(Kcov_ParEsts$ci.upper[15], 3) #upper confidence interval
COV_CIup

# Values for the direct effect
COVdir <- digits(Kcov_ParEsts$est[16], 3) #estimate for the direct effect
COVdir
COVdir_p <- digits(Kcov_ParEsts$pvalue[16], 3) #estimate for the direct effect
COVdir_p
COVdir_CIlo <- digits(Kcov_ParEsts$ci.lower[16], 3) #lower confidence interval
COVdir_CIlo
COVdir_CIup <- digits(Kcov_ParEsts$ci.upper[16], 3) #upper confidence interval
COVdir_CIup

# Values for the total effect 
COVtot <- digits(Kcov_ParEsts$est[17], 3) #estimate for the direct effect
COVtot
COVtot_p <- digits(Kcov_ParEsts$pvalue[17], 3) #estimate for the direct effect
COVtot_p
COVtot_CIlo <- digits(Kcov_ParEsts$ci.lower[17], 3) #lower confidence interval
COVtot_CIlo
COVtot_CIup <- digits(Kcov_ParEsts$ci.upper[17], 3) #upper confidence interval
COVtot_CIup

# Proportion of variance accounted for
COV_Rsq_Y <- percent(Kcov_sum$PE$est[18])
COV_Rsq_Y
COV_Rsq_M <- percent(Kcov_sum$PE$est[19])
COV_Rsq_M
```

### A Figure and a Table

Let's look at a figure to see see if we did what we think we did. And to also get a graphic representation of our results.  The semplot package does this easily, but the figure is more statistical than conceptual and would require more tinkering for a journal article.


```{r semPLOT for model w covs}
semPaths(Kim_fit_covs, #must identiy the model you want to map
         what = "est", #"est" plots the estimates, but keeps it greyscale with no fading
         #whatLabels = "stand", #"stand" changes to standardized values
         layout = 'tree', rotation = 2, #together, puts predictors on left, IVs on right 
         edge.label.cex = 1.00, #font size of parameter values
         #edge.color = "black", #overwrites the green/black coloring
         sizeMan=10, #size of squares/observed/"manifest" variables
         fade=FALSE, #if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals
         esize=2, 
         asize=3,
         #label.prop = .5,
         label.font = 2.5, #controls size (I think) of font for labels
         label.scale = TRUE, #if false, the labels will not scale to fit inside the nodes
         nDigits = 3, #decimal places (default is 2)
         residuals = FALSE,#excludes residuals (and variances) from the path diagram
         nCharNodes = 0, #specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)
         intercepts = FALSE, #gets rid of those annoying triangles (intercepts) in the path diagram)
)
title("Entrepreneurial Withdrawal by eDistress via Negative Affect (& some covariates(")
```

The path coefficients appear to be correct, but this is really a statistical map and doesn't relay the concept of mediation well.

Below is code to create an outfile that could help with creating a table in a word document or spreadsheet. There will be output that is produced with SEM models that won't be relevant for this project.
```{r writes outfile with results for table, results='hide'}
KimCOVTab <- semTable(Kim_fit_covs, columns = c("est", "se", "p", "rsquare"),  columnLabels = c(eststars = "Estimate"), paramSets = c("composites", "loadings", "slopes", "intercepts", "residualvariances"), file = "ESTRESScov_fitTABLE", type = "csv", print.results = TRUE)
```


Table 2  

|Model Coefficients Assessing Cultural Mistrust as a Mediator Between Racial Microaggressions and Well-Being
|:---------------------------------------------------------------------------------------------------------------------------------|

|                         
|:------------------------|:---------------------------------------:|:-----:|:----------------------------------------------------:|
|                         |Cultural Mistrust (M)                    |       |Well-Being (Y)                                        |

|
|:----------------|:-----:|:------------:|:--------------:|:---------------:|:-----:|:-----------:|:--------------:|:-------------:|
|Antecedent       |path   |$B$           |$SE$            |$p$              |path   |$B$          |$SE$            |$p$            |
|constant         |$i_{M}$|`r Cov_Micpt` |`r Cov_Micpt_SE`|`r Cov_Micpt_p`  |$i_{Y}$|`r Cov_Yicpt`|`r Cov_Yicpt_SE`|`r Cov_Yicpt_p`|
|REMS (X)         |$a$    |`r Cova`      |`r CovaSE`      |`r Cova_p`       |$c'$   |`r Covc_p`   |`r CovcSE`      |`r Covc_p_p`   |
|CMI (M)          |       |              |                |                 |$b$    |`r Covb`     |`r CovbSE`     |`r Covb_p`     |
|ANX (Cov)        |       |`r AnxMa`     |`r AnxMse`      |`r AnxM_p`       |       |`r AnxYa`    |`r AnxYse`      |`r AnxY_p`     |

|
|:------------------------|:-----------------------------------------------:|:-----:|:--------------------------------------------:|
|                         |$R^2$ = `r COV_Rsq_M`                            |       |$R^2$ = `r COV_Rsq_Y`                         |                    


### APA Style Write-up

There are varying models for reporting the results of mediation.  The Kim et al. [@kim_racial_2017] writeup is a great example.  Rather than copying it directly, I have modeled my table after the ones in Hayes [-@hayes_introduction_2018] text. You'll notice that information in the table and text are minimally overlapping.  APA style cautions us against redundancy in text and table.

**Results**

A simple mediation model examined the degree to which cultural mistrust mediated the effect of racial microaggressions on psychological well-being.  Using the *lavaan* package (v 0.6-7) in R, coefficients for the each path, the indirect effect, and total effects were calculated. The effect of covariate, anxiety, was mapped onto both the mediator and dependent variable.  These values are presented in Table 3 and illustrated in Figure 3.  Results suggested that `r COV_Rsq_M` of the variance in cultural mistrust and `r COV_Rsq_Y` of the variance in well-being were accounted for by the model.  Supporting the notion of a mediated model, there was a statistically significant indirect effect ($B$ = `r COVind`, $p$ = `r COVind_p`, CI95 `r COV_CIlo` to `r COV_CIup`) in combination with a  non-significant direct effect ($B$ = `r COVdir`, $p$ = `r COVdir_p`, CI95 `r `COVdir_CIlo` to	`r `COVdir_CIup`). Curiously, though, the total effect ($B$ = `r COVtot`, $p$ = `r COVtot_p`, CI95 `COVtot_CIlo`	to `COVtot_CIup`) was also non-significant.


## Residual and Related Questions...

..that you might have; or at least I had, but if had answered them earlier it would have disrupt the flow.

1. Are you sure you can claim a significant indirect effect in the presence of a non-significant total effect?  Hayes [-@hayes_introduction_2018] is.  
   * In the section subtitled, "What about Baron & Kenny" (chapter 4), Hayes argues from both logical/philosophical and statistical perspectives that the size of the total effect does not constrain or determine the size of the indriect effect.  That is, an indicrect effect can be different from zero even when teh total effect is not (pp. 117-119).    
2. The output we get is different from the output in the journal article being used as the research vignette.  Why?  And should we worry about it? 
   * We are simulating data.  This gives us some advantages in that (unless we specify it), we never have missingness and our variables should be normally distributed. Because we are working from means, standard deviations, and correlations, our data will never be the same as the original researcher.  That said, we can compare our results to the journal to *check out work.*  In fact, in this very chapter, I got turned around (e.g., first accidentally swapping the mediator and IV; then using the wrong DV) and was able to compare my work against the journal article to correct my errors. 
3. Some of the statistics you are reporting are different than the ones in Hayes and the ones that use the PROCESS macro (e.g., what happened to the *F* test)?
   *  The default estimator for *lavaan* is maximum likelihood (ML) and Hayes uses ordinary least squares (OLS).  This affects both the values of coefficients, standard errors, AND the type of statistics that are reported. 
   *  You can ask for OLS regression by adding the statement "estimator = "GLS". Even with this option, I have not discovered a way to obtain the *F* tests for the overall model.  Researchers seem to be comfortable with this, even asking for less than we did (e.g., many do not request R square).
   * Best I can tell, researchers who do want this might use a combination of packages, using GLS estimators in *lavaan* (this easily gets them the bootstrapped CIs) and the move to a different regression package to get the intercepts and *F* tests.  If I did this I would triple check to make sure that all the output really lined up.
4. Why did we ignore the traditional fit statistics associated with structural equation modeling (e.g., CFI, RMSEA). 
   * I hesitate to do this with models that do not include latent variables.  Therefore, we asked for an "in-between" amount of info that should be sufficient for publication submission (any editor may have their own preferences and ask for more).
5. What if I have missing data?
   *  When we enter the *lavaan* world we do get options other than multiple imputation.  In today's example we used the "sem" fitting function. Unless otherwise specified, listwise deletion (deleting the entire case when one of its variables is used to estimate the model) is the default in *lavaan*.  If data are MCAR or MAR, you can add the argument *missing = "ml"* (or its alias *missing = "fiml"*).  More here https://users.ugent.be/~yrosseel/lavaan/lavaan2.pdf on the 1.7/Missing data in lavaan slide.
   * That said, the type of estimator matters.  If you estimate your data with GLS (generalized least squares) or WLS (weighted least squares), you are required to have complete data (however you got it).  We used maximum likelihood and, even though we had non-missing data, I used the *missing = "fiml"* code.

   
## Practice Problems

The three problems described below are designed to grow with the subsequent chapters on complex mediation and conditional process analysis (i.e,. moderated mediation). Therefore, I recommend that you select a dataset that includes at least four variables. If you are new to this topic, you may wish to select variables that are all continuously scaled.  The IV and moderator (next chapters) could be categorical (if they are dichotomous, please use 0/1 coding; if they have more than one category it is best if they are ordered).  You will likely encounter challenges that were not covered in this chapter. Search for and try out solutions, knowing that there are multiple paths through the analysis.

The suggested practice problem for this chapter is to conduct a simple mediation.

* There are a number of variables in the dataset.  Swap out one or more variables in the model of simple mediation and compare your solution to the one in the chapter.
* Conduct a simple mediation with data to which you have access. This could include data you simulate on your own or from a published article.

### Problem #1: Rework the research vignette as demonstrated, but change the random seed

If this topic feels a bit overwhelming, simply change the random seed in the data simulation, then rework the problem. This should provide minor changes to the data (maybe in the second or third decimal point), but the results will likely be very similar.

|Assignment Component  
|:---------------------------------------------------------------------------------------------|:-------------: |:------------:|
|1. Assign each variable to the X, Y, or M roles (ok but not required  to include a cov)       |      5         |    _____     |      
|2. Specify and run the lavaan model                                                           |      5         |    _____     |
|3. Use semPlot to create a figure                                                             |      5         |    _____     |
|4. Create a table that includes regression output for the M and Y variables                   |      5         |    _____     |  
|5. Represent your work in an APA-style write-up                                               |      5         |    _____     |          
|6. Explanation to grader                                                                      |      5         |    _____     |   
|7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, & c' paths|      5         |    _____     |
|**Totals**                                                                                    |      35        |    _____     |

### Problem #2:  Rework the research vignette, but swap one or more variables

Use the simulated data, but select one of the other models that was evaluated in the Kim et al. [-@kim_racial_2017] study.  Compare your results to those reported in the mansucript.


|Assignment Component  
|:---------------------------------------------------------------------------------------------|:-------------: |:------------:|
|1. Assign each variable to the X, Y, or M roles (ok but not required  to include a cov)       |      5         |    _____     |      
|2. Specify and run the lavaan model                                                           |      5         |    _____     |
|3. Use semPlot to create a figure                                                             |      5         |    _____     |
|4. Create a table that includes regression output for the M and Y variables                   |      5         |    _____     |  
|5. Represent your work in an APA-style write-up                                               |      5         |    _____     |          
|6. Explanation to grader                                                                      |      5         |    _____     |   
|7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, & c' paths|      5         |    _____     |
|**Totals**                                                                                    |      35        |    _____     |
             
                                                                 

### Problem #3:  Use other data that is available to you

Using data for which you have permission and access (e.g.,  IRB approved data you have collected or from your lab; data you simulate from a published article; data from an open science repository; data from other chapters in this OER), complete a simple mediation.

|Assignment Component  
|:---------------------------------------------------------------------------------------------|:-------------: |:------------:|
|1. Assign each variable to the X, Y, or M roles (ok but not required  to include a cov)       |      5         |    _____     |      
|2. Specify and run the lavaan model                                                           |      5         |    _____     |
|3. Use semPlot to create a figure                                                             |      5         |    _____     |
|4. Create a table that includes regression output for the M and Y variables                   |      5         |    _____     |  
|5. Represent your work in an APA-style write-up                                               |      5         |    _____     |          
|6. Explanation to grader                                                                      |      5         |    _____     |   
|7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, & c' paths|      5         |    _____     |
|**Totals**                                                                                    |      35        |    _____     |
   

```{r sessionInfo 04}
sessionInfo()
```

